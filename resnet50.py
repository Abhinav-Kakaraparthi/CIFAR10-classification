# -*- coding: utf-8 -*-
"""RESNET50.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b6lTbBm5xSzWZ_3TFw6CRX37M2kpzLzy
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.applications.resnet50 import ResNet50
from matplotlib import pyplot as plt
import tensorflow_datasets as tfds



(training_images, training_labels) , (validation_images, validation_labels) = tf.keras.datasets.cifar10.load_data()

def preprocess_image_input(input_images):
  input_images = input_images.astype('float32')
  output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)
  return output_ims

train_X = preprocess_image_input(training_images)
valid_X = preprocess_image_input(validation_images)

def feature_extractor(inputs):
  feature_extractor = tf.keras.applications.resnet.ResNet50(input_shape=(224, 224,3),include_top=False,weights='imagenet')(inputs)
  return feature_extractor

def classifier(inputs):
  x = tf.keras.layers.GlobalAveragePooling2D()(inputs)
  x1 = tf.keras.layers.Flatten()(x)
  x2 = tf.keras.layers.Dense(1024, activation="relu")(x1)
  x3 = tf.keras.layers.Dense(512, activation="relu")(x2)
  x4 = tf.keras.layers.Dense(10, activation="softmax", name="classification")(x3)
  return x4

def final_model(inputs):
  resize = tf.keras.layers.UpSampling2D(size=(7,7))(inputs)
  resnet_feature_extractor = feature_extractor(resize)
  classification_output = classifier(resnet_feature_extractor)
  return classification_output

def define_compile_model():
  inputs = tf.keras.layers.Input(shape=(32,32,3))
  classification_output = final_model(inputs)
  model = tf.keras.Model(inputs=inputs, outputs = classification_output)
  model.compile(loss='sparse_categorical_crossentropy', metrics =['accuracy'])
  return model

model = define_compile_model()
model.summary()
model = define_compile_model()
model.summary()
history = model.fit(train_X, training_labels, epochs=25,steps_per_epoch = 550, validation_data = (valid_X,validation_labels), batch_size=32,validation_steps = 1)
loss, accuracy = model.evaluate(valid_X, validation_labels, batch_size=32)

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.05, 1])
plt.legend(loc='lower right')
plt.show()











